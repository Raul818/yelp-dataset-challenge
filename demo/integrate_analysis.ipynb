{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATASET_DIR = '../../dataset/academic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_review = pd.read_json('../out/yelp_academic_dataset_review_sentiment.json', lines=True)\n",
    "df_review = df_review[df_review['sentiment_value'] != 3]    # remove reviews with invalid sentiment_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_review = df_review.assign(\n",
    "    sentiment_score =\n",
    "        lambda df: df['sentiment_value'] * df['votes'].apply(lambda s: s['useful'] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tip = pd.read_json('../out/yelp_academic_dataset_tip_sentiment.json', lines=True)\n",
    "df_tip = df_tip[df_tip['sentiment_value'] != 3]    # remove reviews with invalid sentiment_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tip = df_tip.assign(\n",
    "    sentiment_score =\n",
    "        lambda df: df['sentiment_value'] * (df['likes'] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_business = pd.read_json(DATASET_DIR + '/yelp_academic_dataset_business.json', lines=True)\n",
    "\n",
    "business_filters = (df_business['review_count'].apply(lambda rc: rc >= 20)\n",
    "                    & df_business['categories'].apply(lambda cs: 'Restaurants' in cs))\n",
    "#                     & df_business['open'])\n",
    "\n",
    "df_business_restaurants = (df_business[business_filters]\n",
    "                           .reset_index(drop=True)[['business_id', 'stars', 'review_count', 'hours', 'city', 'attributes']])\n",
    "\n",
    "# round the stars\n",
    "df_business_restaurants['stars'] = df_business_restaurants['stars'].apply(np.round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_avg_score_of_business(series, bid, col):\n",
    "    if bid in series.groups:\n",
    "        group = series.get_group(bid)\n",
    "        return group[col].mean()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "new_col_for_score_dfs = [(df_review, 'sentiment_score', 'review_sentiment_rating'),\n",
    "                         (df_review, 'stars', 'review_star_rating'),\n",
    "                         (df_tip, 'sentiment_score', 'tip_rating')]\n",
    "\n",
    "def add_evluation_score_to_business(new_col_for_score_df):\n",
    "    series = new_col_for_score_df[0].groupby('business_id')\n",
    "    global df_business_restaurants\n",
    "    df_business_restaurants[new_col_for_score_df[2]] = df_business_restaurants['business_id'].apply(\n",
    "        lambda bid: get_avg_score_of_business(series, bid, new_col_for_score_df[1]))\n",
    "\n",
    "for item in new_col_for_score_dfs:\n",
    "    add_evluation_score_to_business(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_checkin = pd.read_json('../out/business_with_checkin_count.json')\n",
    "\n",
    "def get_checkin_count(bid):\n",
    "    row = df_checkin[df_checkin['business_id'] == bid]\n",
    "    if not row.empty:\n",
    "        return row.iloc[0]['checkin_count']\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df_business_restaurants['checkin_rating'] = df_business_restaurants['business_id'].apply(\n",
    "    lambda bid: get_checkin_count(bid))\n",
    "\n",
    "df_business_restaurants['checkin_rating'] = df_business_restaurants['review_count'] / df_business_restaurants['checkin_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_ratings_cols = ['review_sentiment_rating',\n",
    "                         'review_star_rating',\n",
    "                         'tip_rating',]\n",
    "#                          'checkin_rating']\n",
    "\n",
    "business_nan_filters = np.ones(len(df_business_restaurants), dtype=bool)\n",
    "for col in business_ratings_cols:\n",
    "    business_nan_filters &= np.invert(np.isnan(df_business_restaurants[col]))\n",
    "\n",
    "df_business_restaurants = df_business_restaurants[business_nan_filters].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_BINS_OF_RATING = 72\n",
    "\n",
    "def score_to_rating(col):\n",
    "    bins = np.linspace(\n",
    "        df_business_restaurants[col].min(),\n",
    "        df_business_restaurants[col].max(),\n",
    "        num=NUM_BINS_OF_RATING)\n",
    "\n",
    "    df_business_restaurants[col] = df_business_restaurants[col].apply(\n",
    "        # return the rating which is closeat to the score.\n",
    "        lambda score: np.argmin(np.abs(bins - score)) + 1)\n",
    "    \n",
    "score_cols = ['review_sentiment_rating', 'review_star_rating', 'tip_rating', 'checkin_rating']\n",
    "\n",
    "# convert score to rating\n",
    "for col in score_cols:\n",
    "    score_to_rating(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "    \n",
    "df_business_restaurants = df_business_restaurants.assign(working_type=lambda x: x['hours'])\n",
    "\n",
    "WORKING_TYPES = {\n",
    "    \"WEEKEND_TYPE\": \"weekend\",\n",
    "    \"BREAKFAST_TYPE\": \"breakfast\",\n",
    "    \"LUNCH_TYPE\": \"lunch\",\n",
    "    \"AFTER_LUNCH_TYPE\": \"after-lunch\",\n",
    "    \"DINNER_TYPE\": \"dinner\",\n",
    "    \"NIGHT_TYPE\": \"night\",\n",
    "}\n",
    "\n",
    "breakfast = time(8)\n",
    "lunch = time(12)\n",
    "after_lunch = time(15)\n",
    "dinner = time(18)\n",
    "night = time(0)\n",
    "\n",
    "def in_between(start, end, check):\n",
    "    if start == end: # 24 hours\n",
    "        return True\n",
    "    if start < end:\n",
    "        return start <= check < end\n",
    "    else: # over midnight e.g., 23:30-04:15\n",
    "        return start <= check or check < end\n",
    "\n",
    "TYPE_THRESHOLD = 1\n",
    "def get_available_working_type(c, wt):\n",
    "    if c >= TYPE_THRESHOLD:\n",
    "        return [wt]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def spec_hours_to_type(s):\n",
    "    types = []\n",
    "    \n",
    "    breakfast_count = 0\n",
    "    lunch_count = 0\n",
    "    after_lunch_count = 0\n",
    "    dinner_count = 0\n",
    "    night_count = 0\n",
    "\n",
    "    for day in s:\n",
    "        \n",
    "        clo = s[day]['close']\n",
    "        op = s[day]['open']\n",
    "\n",
    "        h, m = clo.split(':')\n",
    "        clo_t = time(int(h), int(m))\n",
    "\n",
    "        h, m = op.split(':')\n",
    "        op_t = time(int(h), int(m))\n",
    "        \n",
    "        breakfast_count += int(in_between(op_t, clo_t, breakfast))\n",
    "        lunch_count += int(in_between(op_t, clo_t, lunch))\n",
    "        after_lunch_count += int(in_between(op_t, clo_t, after_lunch))\n",
    "        dinner_count += int(in_between(op_t, clo_t, dinner))\n",
    "        night_count += int(in_between(op_t, clo_t, night))\n",
    "        \n",
    "        if (day in ['Saturday', 'Sunday']) and (WORKING_TYPES[\"WEEKEND_TYPE\"] not in types):\n",
    "            types.append(WORKING_TYPES[\"WEEKEND_TYPE\"])\n",
    "    \n",
    "    types += get_available_working_type(breakfast_count, WORKING_TYPES[\"BREAKFAST_TYPE\"])\n",
    "    types += get_available_working_type(lunch_count, WORKING_TYPES[\"LUNCH_TYPE\"])\n",
    "    types += get_available_working_type(after_lunch_count, WORKING_TYPES[\"AFTER_LUNCH_TYPE\"])\n",
    "    types += get_available_working_type(dinner_count, WORKING_TYPES[\"DINNER_TYPE\"])\n",
    "    types += get_available_working_type(night_count, WORKING_TYPES[\"NIGHT_TYPE\"])\n",
    "    \n",
    "    return join_types(types)\n",
    "\n",
    "def hours_to_type(s):\n",
    "    if isinstance(s, str):\n",
    "        return s\n",
    "    \n",
    "    if s:\n",
    "        return spec_hours_to_type(s)\n",
    "    else:\n",
    "        return join_types(WORKING_TYPES.values())\n",
    "\n",
    "def join_types(ts):\n",
    "    # reorder\n",
    "    ordered_types = []\n",
    "    for t in WORKING_TYPES.values():\n",
    "        if t in ts:\n",
    "            ordered_types.append(t)\n",
    "    return '_'.join(ordered_types)\n",
    "\n",
    "\n",
    "df_business_restaurants['working_type'] = df_business_restaurants['working_type'].apply(hours_to_type)\n",
    "working_type_set = df_business_restaurants['working_type'].unique()\n",
    "\n",
    "DEFAULT_TYPE = 'default'\n",
    "def extract_value_from_attrs(attrs, k):\n",
    "    if k in attrs:\n",
    "        return attrs[k]\n",
    "    else:\n",
    "        return DEFAULT_TYPE\n",
    "    \n",
    "def filter_from_attr_val(attrs, k, v):\n",
    "    return k in attrs and attrs[k] == v\n",
    "\n",
    "def filter_no_attr(attrs, k):\n",
    "    return k not in attrs\n",
    "\n",
    "attr_types_set = {\n",
    "    'Accepts Credit Cards': [],\n",
    "    'Alcohol': [],\n",
    "    'Caters': [],\n",
    "    'Noise Level': [],\n",
    "    'Price Range': [],\n",
    "    'Take-out': []\n",
    "}\n",
    "\n",
    "for t in attr_types_set:\n",
    "    tdf = df_business_restaurants['attributes'].apply(lambda a: extract_value_from_attrs(a, t))\n",
    "    attr_types_set[t] = tdf.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ATTR_MARK = '|attr'\n",
    "\n",
    "def train(training_dataset):\n",
    "    business_restaurants_group_by_stars = training_dataset.groupby('stars')\n",
    "\n",
    "    business_restaurants_of_stars = {}\n",
    "    for star in business_restaurants_group_by_stars.groups:\n",
    "        business_restaurants_of_stars[star] = business_restaurants_group_by_stars.get_group(star)\n",
    "\n",
    "    prior_of_stars = {}\n",
    "    for star in business_restaurants_of_stars:\n",
    "        prior_of_stars[star] = len(business_restaurants_of_stars[star]) * 1.0 / len(training_dataset)\n",
    "\n",
    "    num_working_types = len(working_type_set)\n",
    "    num_cities = len(training_dataset['city'].unique())\n",
    "    \n",
    "    features_of_stars = {}\n",
    "    \n",
    "    def set_value_in_features_dict(k, star, v):\n",
    "        if k not in features_of_stars:\n",
    "            features_of_stars[k] = {}\n",
    "        features_of_stars[k][star] = v\n",
    "\n",
    "    for star in business_restaurants_of_stars:\n",
    "        business_restaurants_of_star_df = business_restaurants_of_stars[star]\n",
    "        num_business = len(business_restaurants_of_star_df)\n",
    "\n",
    "        # count frequency of different type\n",
    "        types_freq = {}\n",
    "\n",
    "        working_type_of_business = business_restaurants_of_star_df.groupby('working_type')\n",
    "        for wt in working_type_of_business.groups:\n",
    "            # we use the add-one or Laplace smoothing\n",
    "            types_freq[wt] = (len(working_type_of_business.get_group(wt)) + 1.0) / (num_business + num_working_types)\n",
    "\n",
    "        # this value is for working type not present in this star level\n",
    "        types_freq[DEFAULT_TYPE] = 1.0 / (num_business + num_working_types)\n",
    "\n",
    "        set_value_in_features_dict('working_type', star, types_freq)\n",
    "\n",
    "\n",
    "        # count frequency of different city\n",
    "        city_freq = {}\n",
    "\n",
    "        # Now group them by city\n",
    "        city_of_business = business_restaurants_of_star_df.groupby('city')\n",
    "        for city in city_of_business.groups:\n",
    "            # we use the add-one or Laplace smoothing\n",
    "            city_freq[city] = (len(city_of_business.get_group(city)) + 1.0) / (num_business + num_cities)\n",
    "\n",
    "        # this value is for cities not in the a specify \"group of star\",\n",
    "        # e.g. city \"glendale\" is not in group of star 1\n",
    "        city_freq[DEFAULT_TYPE] = 1.0 / (num_business + num_cities)\n",
    "\n",
    "        set_value_in_features_dict('city', star, city_freq)\n",
    "\n",
    "\n",
    "        # count frequency of attrs\n",
    "        for a in attr_types_set:\n",
    "            attr_freq = {}\n",
    "            for t in attr_types_set[a]:\n",
    "                if t != DEFAULT_TYPE:\n",
    "                    num = len(business_restaurants_of_star_df[business_restaurants_of_star_df['attributes'].apply(lambda attrs: filter_from_attr_val(attrs, a, t))])\n",
    "                else:\n",
    "                    num = len(business_restaurants_of_star_df[business_restaurants_of_star_df['attributes'].apply(lambda attrs: filter_no_attr(attrs, a))])\n",
    "\n",
    "                attr_freq[t] = (num + 1.0) / (num_business + len(attr_types_set[a]))\n",
    "\n",
    "            set_value_in_features_dict(a + ATTR_MARK, star, attr_freq)\n",
    "\n",
    "\n",
    "        # count frequency of ratings\n",
    "        for rt_col in business_ratings_cols:\n",
    "            rating_freq = {}\n",
    "\n",
    "            rating_of_business = business_restaurants_of_star_df.groupby(rt_col)\n",
    "            for rt in rating_of_business.groups:\n",
    "                rating_freq[rt] = (len(rating_of_business.get_group(rt)) + 1.0) / (num_business + NUM_BINS_OF_RATING)\n",
    "\n",
    "                rating_freq[DEFAULT_TYPE] = 1.0 / (num_business + NUM_BINS_OF_RATING)\n",
    "\n",
    "            set_value_in_features_dict(rt_col, star, rating_freq)\n",
    "            \n",
    "    return prior_of_stars, features_of_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def calc_probs(r, prior_of_stars, features_of_stars):\n",
    "    probs_of_stars = {}\n",
    "    \n",
    "    for star in prior_of_stars:\n",
    "        prob = np.log(prior_of_stars[star])\n",
    "        \n",
    "        for f in features_of_stars:\n",
    "            if not f.endswith(ATTR_MARK):\n",
    "                prob += np.log(features_of_stars[f][star].get(r[f], features_of_stars[f][star][DEFAULT_TYPE]))\n",
    "            else:\n",
    "                prob += np.log(features_of_stars[f][star].get(\n",
    "                        extract_value_from_attrs(r['attributes'], f[:-len(ATTR_MARK)]), features_of_stars[f][star].get(DEFAULT_TYPE, np.nan)))\n",
    "    \n",
    "        probs_of_stars[star] = prob\n",
    "        \n",
    "    return probs_of_stars\n",
    "\n",
    "def predict(stars, probs):\n",
    "    sorted_probs = sorted(probs.items(), key=operator.itemgetter(1))\n",
    "    return sorted_probs[-1][0]\n",
    "    \n",
    "def correctness(stars, estimated_stars):\n",
    "    return stars == estimated_stars\n",
    "    \n",
    "def distance(stars, estimated_stars):\n",
    "    return abs(stars - estimated_stars)\n",
    "\n",
    "def test(test_dataset, prior_of_stars, features_of_stars):\n",
    "    test_dataset['stars_probs'] = test_dataset.apply(lambda r: calc_probs(r, prior_of_stars, features_of_stars), axis=1)\n",
    "\n",
    "    test_dataset['estimated_stars'] = test_dataset.apply(lambda r: predict(r['stars'], r['stars_probs']), axis=1)\n",
    "    test_dataset['correctness'] = test_dataset.apply(lambda r: correctness(r['stars'], r['estimated_stars']), axis=1)\n",
    "    test_dataset['distance'] = test_dataset.apply(lambda r: distance(r['stars'], r['estimated_stars']), axis=1)\n",
    "\n",
    "\n",
    "    corrects = len(test_dataset[test_dataset['correctness'] == True])\n",
    "    print('accuracy is ' + str(corrects * 1.0 / len(test_dataset)))\n",
    "\n",
    "    print('average distance is ' + str(test_dataset['distance'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.938472942920682\n",
      "average distance is 0.0637509266123\n"
     ]
    }
   ],
   "source": [
    "## Split dataset and start train\n",
    "df_training_business_restaurants = df_business_restaurants.sample(frac=0.8)\n",
    "prior_of_stars, features_of_stars = train(df_training_business_restaurants)\n",
    "\n",
    "## Evaluate on the test dataset\n",
    "df_test_business_restaurants = df_business_restaurants[~df_business_restaurants.isin(df_training_business_restaurants)].dropna()\n",
    "test(df_test_business_restaurants, prior_of_stars, features_of_stars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
